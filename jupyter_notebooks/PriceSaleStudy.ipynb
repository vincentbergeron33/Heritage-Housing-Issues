{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Price Sale Study**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer business requirement 1:\n",
        "    * Perform a correlation and/or PPS study to investigate the most relevant variables correlated to the sale price.\n",
        "    * Visualize these variables against the sale price and summarize.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/HousingPricesData.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate analisys and plot that answers business requirement 1 and can be used to build the Streamlit App\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* outputs/datasets/collection/InheritedHouses.csv is not used in this Notebook since it has the same structure as the House Price Data\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "We can conclude the below from the correlations and plots:\n",
        "\n",
        "* When 1stFlrSF increase, the SalePrice tend to increase.\n",
        "* When GarageArea increase, the SalePrice tend to increase. The house without a garage (GarageArea = 0) are worth <=200 000.\n",
        "* When GrLivArea increase, the SalePrice tend to increase.\n",
        "* The houses with the KitchenQual_Ex selection are mainly the houses with a Saleprice of <400 000.\n",
        "* The houses with the KitchenQual_TA selection are mainly the houses with a Saleprice of <300 000.\n",
        "* When Overallqual increase, the SalePrice tend to increase. Following the Spearman and Pearson, it most correlated feature to the target.\n",
        "* When TotalBsmtSF increase, the SalePrice tend to increase.\n",
        "* When YearBuilt increase, the SalePrice tend to increase. This trend goes more exponential from the year 1980.\n",
        "* When YearRemodAdd increase, the SalePrice tend to increase. This trend goes more exponential from the year 1980."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df1 = (pd.read_csv(\"outputs/datasets/collection/HousePriceRecord.csv\"))\n",
        "df1.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "pandas_report = ProfileReport(df=df1, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can learn the below from the Profile Report above:\n",
        "* 1stFlrSF: 0 missing data, range of data between 334-4692, data type integer and normally distributed.\n",
        "* 2sdFlrSF: **86 missing data (5.9%)**, range of data between 0-2065, 781 0s (53.05%), **the 0s mean there is no second floor in those houses**, data type integer.\n",
        "* BedroomAbvGr: **99 missing datas (6.8%)**, range of data between 0-8, data type integer.\n",
        "* BsmtExposure: 0 missing data, categorical data with variables [none, mn, gd, av, no], **none and no likely to be the same.**\n",
        "* BsmtFinSF1: 0 missing data, range of data between 0-5644, 467 0s (32%), **the 0s mean there is no basement for those houses**, data type integer.\n",
        "* BsmtFinType1: **114 missing data (7.8%)** categorical data with variable [glq, blq, alq, unf, lwq, rec, none], **missing data likely to be none**.\n",
        "* BsmtUnfSF: 0 missing data, range of data between 0-2336, 118 0s (8.1%), data type integer.\n",
        "* EnclosedPorch: **1324 missing data (90.7%)**, range of data between 0-286, 116 0s (7.9%), data type integer.\n",
        "* GarageArea: 0 missing data, range of data between 0-1418, 81 0s (5.5%), date type integer, **the 0s mean there is no garage for those houses**.\n",
        "* GarageFinish: **162 missing data (11.1%)**, categorical data with variable [rfn, unf, fin, none], **none means there is no garage for those houses.**\n",
        "* GarageYrBlt: **81 missing data (5.5%)**,  range of data between 1990-2010, data type integer, **the missing date is exactly the number of 0s in Garage Area meaning the missing data is the date with no Garage.**\n",
        "* GrLivArea: 0 missing data, range of data between 334-5642, data type integer, **well distributed.**\n",
        "* KitchenQual: 0 missing data, categorical data with variable [ta, gd, fa, ex].\n",
        "* LotArea: 0 missing data, range of data between 1300-215245, data type integer.\n",
        "* LotFrontage: **259 missing data (17.7%)**, range of data between 21-313, data type integer.\n",
        "* MasVnrArea: **8 missing data (0.5%)**, range of data between 0-1600, 861 0s (59%).\n",
        "* OpenPorchSF: 0 missing data, range of data between 0-547, 656 0s (44.9%), data type integer.\n",
        "* OverallCond: 0 missing data, range of data between 1-9, data type integer.\n",
        "* OverallQual: 0 missing data, range of data between 1-10, data type integer.\n",
        "* TotalBsmtSF: 0 missing data, range of data between 0-6110, 37 0s (2.5%), data type integer, **the 0s mean there is no basement for those houses.**\n",
        "* WoodDeckSF: **1305 missing data (89.4%)**, range of data between 0-736, 78 0s (5.3%), data type integer, **this row have been avoided during the data production and could corrupted the data because of the small amount of actual data we have, we would suggest to drop this feature for a better performance of the model.**\n",
        "* YearBuilt: 0 missing data, range of data between 1872-2010, data type integer.\n",
        "* YearRemodAdd: 0 missing data, range of data between 1950-2010, data type integer. \n",
        "* SalePrice: 0 missing data, range of data between 34900-755000, data type integer, **SalePrice is the target of this project.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Replace missing data\n",
        "## Analysis of each missing data in variables\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. 2sdFlrSF 86 missing data (5.9%), range of data between 0-2065, 781 0s (53.05%), **the 0s mean there is no second floor in those houses**, data type integer.**\n",
        "\n",
        "Most likely this data entry have been avoided because there was no second floor. Following the Data Culture and CRISP-DM Workflow we would take 2 solution to the team:\n",
        " * ArbitraryNumberImputer with a arbitraty number of 0 because of the reason above.\n",
        " * MeanMedianImputer with a imputation_method of median.\n",
        "\n",
        "In this situation since the values are not well distributed, the 0s counts for 53% of the values and the likelihood that this entry have been avoided because the house has only one floor, the team has decided to use an Arbitrary number of 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2. BedroomAbvGr: 99 missing datas (6.8%), range of data between 0-8, data type integer.**\n",
        "\n",
        "Since every house have bedrooms, the best way to fill the data here is MeanMedianImputer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. BsmtFinType1: 114 missing data (7.8%) categorical data with variable [glq, blq, alq, unf, lwq, rec, none].**\n",
        "\n",
        "By looking at the other feature linked to BsmtFinType1, we cannot find any link between them discover what is the missing data. For this reason we propose to use CategoricalImputer with imputation_method='frequent'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1['BsmtExposure'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1['BsmtUnfSF'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1['BsmtFinType1'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4. EnclosedPorch: 1324 missing data (90.7%), range of data between 0-286, 116 zeros.**\n",
        "\n",
        "For this feature, we take into consideration that an enclosed Porch is a rare feature on a house and that during the data production, this row has been avoided because there was not a Enclosed Porch within the house. For this reason we propose and ArbitraryNumberImputer with a arbitraty number of 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**5. GarageFinish: 162 missing data (11.1%), categorical data with variable [rfn, unf, fin, none], none means there is no garage for those houses.**\n",
        "\n",
        "After looking at the other feature related to GaraFinish, we cannot find any link between them discover what is the missing data. For this reason we propose to use CategoricalImputer with imputation_method='frequent'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1['GarageFinish'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1['GarageArea'].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**6. GarageYrBlt: 81 missing data (5.5%),  range of data between 1990-2010, data type integer** \n",
        "\n",
        "The missing date is exactly the number of 0s in Garage Area meaning the missing data is the date with no Garage. For this reason we propose a MeanMedianImputer to minimize the impact this data will have on the analisis instead of putting a arbitrary number of 0 by exemple who would create a disturbed distribution or worst dropping the rows which will remove all houses without a garage as a garage will hypothetically have an impact on the PriceSale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1['GarageArea'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**7. LotFrontage: 259 missing data (17.7%), range of data between 21-313, data type integer.**\n",
        "\n",
        "Since every house have frontage, the best way to fill the data here is MeanMedianImputer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**8. MasVnrArea: 8 missing data (0.5%), range of data between 0-1600, 861 0s (59%).**\n",
        "\n",
        "Since 59% of the values are 0s we will use an ArbitraryNumberImputer with a arbitraty number of 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**9. WoodDeckSF: 1305 missing data (89.4%), range of data between 0-736, 78 0s (5.3%), data type integer**\n",
        "\n",
        "This row have been avoided during the data production. The values are poorly distributed. we suggest to drop this feature for a better performance of the model. Before droping the feature, we will run a MeanMedianImputer to confirm it doesn't have important correlation with the other features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Getting the data ready for Correlation Study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the pipeline following the suggestion from the analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.imputation import ArbitraryNumberImputer\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "from feature_engine.imputation import CategoricalImputer\n",
        "\n",
        "pipeline_missing_data = Pipeline([\n",
        "      ( 'arbitrary_number_zero',  ArbitraryNumberImputer(arbitrary_number=0,\n",
        "                                                  variables=['2ndFlrSF', 'EnclosedPorch', 'MasVnrArea']) ),\n",
        "\n",
        "      ( 'median',  MeanMedianImputer(imputation_method='median',\n",
        "                                     variables=['BedroomAbvGr' , 'GarageYrBlt',\n",
        "                                                'LotFrontage', 'WoodDeckSF']) ),\n",
        "      ( 'categorical_imputer', CategoricalImputer(imputation_method='frequent', \n",
        "                                                  variables=['BsmtFinType1', 'GarageFinish']) ),\n",
        "\n",
        "])\n",
        "pipeline_missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We fit and transform the database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_missing_data.fit(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1_filled = pipeline_missing_data.transform(df1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We confirm that there are no more missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1_filled.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1_filled.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We transform the data to get it ready for the correlation study using OneHotEncore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.encoding import OneHotEncoder\n",
        "encoder = OneHotEncoder(variables=df1_filled.columns[df1_filled.dtypes=='object'].to_list(), drop_last=False)\n",
        "df_ohe = encoder.fit_transform(df1_filled)\n",
        "print(df_ohe.shape)\n",
        "df_ohe.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Correlation Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We run .corr for both method Spearman and Pearson to check the correlation between SalePrice and the features. We sort the value using the absolute value to see the most correlated value on the top of the list whichever is positive or negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_spearman = df_ohe.corr(method='spearman')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_spearman"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_pearson = df_ohe.corr(method='pearson')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_pearson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For both method we notice high or moderate levels of correlation between SalePrice (Target) and a given variable (feature). We will keep all variable with a abs correlation of >0.5 which are 9 first variables in both variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n = 9\n",
        "set(corr_pearson[:top_n].index.to_list() + corr_spearman[:top_n].index.to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The correlation study will investigate the following:\n",
        "* Impact on Saleprice value when 1stFlrSF change.\n",
        "* Impact on Saleprice value when GarageArea change.\n",
        "* Impact on Saleprice value when GrLivArea change.\n",
        "* Impact on Saleprice value for KitchenQual_Ex selection.\n",
        "* Impact on Saleprice value for KitchenQual_TA selection.\n",
        "* Impact on Saleprice value when Overallqual change.\n",
        "* Impact on Saleprice value when TotalBsmtSF change.\n",
        "* Impact on Saleprice value when YearBuilt change.\n",
        "* Impact on Saleprice value when YearRemodAdd change.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_to_study =  ['1stFlrSF', 'GarageArea', 'GarageYrBlt', 'GrLivArea', 'KitchenQual_Ex', 'KitchenQual_TA',\n",
        "                  'OverallQual', 'TotalBsmtSF', 'YearBuilt', 'YearRemodAdd']\n",
        "vars_to_study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EDA on selected variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We read and inspect house_prices_record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_eda = df_ohe.filter(vars_to_study + ['SalePrice'])\n",
        "df_eda.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variables Distribution by Churn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will first plot the numerical value to see the correlation of their value compared to the SalePrice value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "\n",
        "def plot_categorical(df, col, target_var):\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    sns.scatterplot(data=df, x=target_var, hue=col, order=df[col].value_counts().index)\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_numerical(df, col, target_var):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.scatterplot(data=df, x=col, y=target_var)\n",
        "    plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "target_var = 'SalePrice'\n",
        "for col in vars_to_study:\n",
        "    if df_eda[col].dtype == 'object':\n",
        "        plot_categorical(df_eda, col, target_var)\n",
        "        print(\"\\n\\n\")\n",
        "    else:\n",
        "        plot_numerical(df_eda, col, target_var)\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parallet Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are now doing a Parallel Plot to understand how the categorical features are spread accross the target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.discretisation import ArbitraryDiscretiser\n",
        "import numpy as np\n",
        "sale_price_map = [-np.Inf, 100000, 200000, 300000, 400000, 500000, 600000, np.Inf]\n",
        "disc = ArbitraryDiscretiser(binning_dict={'SalePrice': sale_price_map})\n",
        "df_parallel = disc.fit_transform(df_eda)\n",
        "df_parallel.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_parallel['SalePrice'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a label for the SalePrice categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_classes = len(sale_price_map) - 1\n",
        "classes_ranges = disc.binner_dict_['SalePrice'][1:-1]\n",
        "\n",
        "labels_map = {}\n",
        "for n in range(0, n_classes):\n",
        "    if n == 0:\n",
        "        labels_map[n] = f\"<{classes_ranges[0]}\"\n",
        "    elif n == n_classes-1:\n",
        "        labels_map[n] = f\"+{classes_ranges[-1]}\"\n",
        "    else:\n",
        "        labels_map[n] = f\"{classes_ranges[n-1]} to {classes_ranges[n]}\"\n",
        "\n",
        "labels_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_parallel['SalePrice'] = df_parallel['SalePrice'].replace(labels_map)\n",
        "df_parallel.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_cat_to_study = vars_to_study =  ['KitchenQual_Ex', 'KitchenQual_TA',\n",
        "                  'OverallQual']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def plot_categorical(df, col, target_var):\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    sns.countplot(data=df, x=col, hue=target_var)\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "target_var = 'SalePrice'\n",
        "for col in vars_cat_to_study:\n",
        "        plot_categorical(df_parallel, col, target_var)\n",
        "        print(\"\\n\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conslusions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can conclude the below from the correlations and plots:\n",
        "\n",
        "* When 1stFlrSF increase, the SalePrice tend to increase.\n",
        "* When GarageArea increase, the SalePrice tend to increase. The house without a garage (GarageArea = 0) are worth <=200 000.\n",
        "* When GrLivArea increase, the SalePrice tend to increase.\n",
        "* The houses with the KitchenQual_Ex selection are mainly the houses with a Saleprice of <400 000.\n",
        "* The houses with the KitchenQual_TA selection are mainly the houses with a Saleprice of <300 000.\n",
        "* When Overallqual increase, the SalePrice tend to increase. Following the Spearman and Pearson, it most correlated feature to the target.\n",
        "* When TotalBsmtSF increase, the SalePrice tend to increase.\n",
        "* When YearBuilt increase, the SalePrice tend to increase. This trend goes more exponential from the year 1980.\n",
        "* When YearRemodAdd increase, the SalePrice tend to increase. This trend goes more exponential from the year 1980."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are pushing the Database without missing data for the next step of Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/filled') # create outputs/datasets/collection folder\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "\n",
        "df1_filled.to_csv(f\"outputs/datasets/filled/HousePriceRecordFilled.csv\",index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**HousePriceRecord and Inherited_houses have been pushed in the folder outputs/datasets/collection**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
